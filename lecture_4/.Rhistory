set.seed(1)
ntrees <- 50
XLIM <- range(polls_2008$day)
polls_2008 %>%
mutate(y_hat = predict(fit, newdata = polls_2008)) %>% ggplot() +
geom_point(aes(day, margin)) + geom_line(aes(day, y_hat), col="red")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE, fig.align="center")
library(caret)
library(tidyverse)
library(kableExtra)
library(gridExtra)
img_path <- "figs/treeFigs/"
# Chunk 2
library(tidyverse)
library(dslabs)
data("olive")
olive <- select(olive, -area) #remove the `area` column--don't use it
names(olive)
# Chunk 3
olive %>% head() %>%
knitr::kable() %>% kable_styling(font_size =7)
# Chunk 4
table(olive$region)
# Chunk 5: olive-knn
library(caret)
fit <- train(region ~ .,  method = "knn", data = olive,
tuneGrid = data.frame(k = seq(1, 15, 2)))
ggplot(fit)
# Chunk 6: olive-eda
olive %>% gather(fatty_acid, percentage, -region) %>%
ggplot(aes(region, percentage, fill = region)) +
geom_boxplot() +
facet_wrap(~fatty_acid, scales = "free", ncol = 4) +
theme(axis.text.x = element_blank(), legend.position="bottom")
# Chunk 7: olive-two-predictors
olive %>%
ggplot(aes(eicosenoic, linoleic, color = region)) +
geom_point() +
geom_vline(xintercept = 0.065, lty = 2) +
geom_segment(x = -0.2, y = 10.54, xend = 0.065, yend = 10.54,
color = "black", lty = 2)
# Chunk 8: olive-tree
library(caret)
library(rpart)
train_rpart <- train(region ~ ., method = "rpart", data = olive)
plot(train_rpart$finalModel, margin = 0.1)
text(train_rpart$finalModel, cex = 0.75)
# Chunk 9: polls-2008-again
data("polls_2008")
polls_2008 %>%
ggplot() + geom_point(aes(day, margin))
# Chunk 10
library(rpart)
fit <- rpart(margin ~ ., data = polls_2008)
# Chunk 11: polls-2008-tree
plot(fit, margin = 0.1)
text(fit, cex = 0.75)
# Chunk 12: polls-2008-tree-fit
polls_2008 %>%
mutate(y_hat = predict(fit)) %>% ggplot() +
geom_point(aes(day, margin)) + geom_step(aes(day, y_hat), col="red")
# Chunk 13: polls-2008-tree-over-fit
fit <- rpart(margin ~ ., data = polls_2008,
control = rpart.control(cp = 0, minsplit = 2))
polls_2008 %>%
mutate(y_hat = predict(fit)) %>% ggplot() +
geom_point(aes(day, margin)) +  geom_step(aes(day, y_hat), col="red")
# Chunk 14: polls-2008-prune
pruned_fit <- prune(fit, cp = 0.01)
polls_2008 %>% mutate(y_hat = predict(pruned_fit)) %>% ggplot() +
geom_point(aes(day, margin)) + geom_step(aes(day, y_hat), col="red")
# Chunk 15: polls-2008-tree-train
library(caret)
train_rpart <- train(margin ~ ., method = "rpart",
tuneGrid = data.frame(cp = seq(0, 0.05, len = 25)),
data = polls_2008)
ggplot(train_rpart)
# Chunk 16: polls-2008-final-model
plot(train_rpart$finalModel, margin = 0.1)
text(train_rpart$finalModel, cex = 0.75)
# Chunk 17: polls-2008-final-fit
polls_2008 %>%
mutate(y_hat = predict(train_rpart)) %>% ggplot() +
geom_point(aes(day, margin)) +
geom_step(aes(day, y_hat), col="red")
# Chunk 18
data("mnist_27")
plot_cond_prob <- function(p_hat=NULL){
tmp <- mnist_27$true_p
if(!is.null(p_hat)){
tmp <- mutate(tmp, p=p_hat)
}
tmp %>% ggplot(aes(x_1, x_2, z=p, fill=p)) +
geom_raster(show.legend = FALSE) +
scale_fill_gradientn(colors=c("#F8766D","white","#00BFC4")) +
stat_contour(breaks=c(0.5),color="black")
}
p1 <- mnist_27$train %>%
ggplot(aes(x_1,x_2,col=y)) + geom_point() +
ggtitle("Scatterplot of the data")
p2 <- plot_cond_prob() + ggtitle("True conditional probability")
grid.arrange(p1, p2, nrow=1)
# Chunk 19
plot_cond_prob <- function(p_hat=NULL){
tmp <- mnist_27$true_p
if(!is.null(p_hat)){
tmp <- mutate(tmp, p=p_hat)
}
tmp %>% ggplot(aes(x_1, x_2, z=p, fill=p)) +
geom_raster(show.legend = FALSE) +
scale_fill_gradientn(colors=c("#F8766D","white","#00BFC4")) +
stat_contour(breaks=c(0.5),color="black")
}
# Chunk 20: mnist-27-tree
train_rpart <- train(y ~ ., method = "rpart", data = mnist_27$train,
tuneGrid = data.frame(cp = seq(0.0, 0.1, len = 30)))
plot(train_rpart)
# Chunk 21
y_hat <- predict(train_rpart, mnist_27$test)
confusionMatrix(y_hat, mnist_27$test$y)$overall["Accuracy"]
# Chunk 22: rf-cond-prob
library(gridExtra)
p1 <- plot_cond_prob() + ggtitle("True conditional probability")
p2 <- plot_cond_prob(predict(train_rpart, newdata = mnist_27$true_p, type = "prob")[,2]) +
ggtitle("Decision Tree")
grid.arrange(p2, p1, nrow=1)
# Chunk 23: polls-2008-rf
library(randomForest)
fit <- randomForest(margin~., data = polls_2008)
fit
# Chunk 24: more-trees-better-fit
plot(fit,main='')
# Chunk 25: polls-2008-rf-fit
polls_2008 %>%
mutate(y_hat = predict(fit, newdata = polls_2008)) %>% ggplot() +
geom_point(aes(day, margin)) + geom_line(aes(day, y_hat), col="red")
# Chunk 26: rf-animation
set.seed(1)
ntrees <- 50
XLIM <- range(polls_2008$day)
YLIM <- range(polls_2008$margin)
if(!file.exists(file.path(img_path,"rf.gif"))){
sum <- rep(0,nrow(polls_2008))
res <- vector("list", ntrees)
animation::saveGIF({
for(i in 0:ntrees){
if(i==0){
with(polls_2008, plot(day, margin, pch = 1, main = "Data", xlim=XLIM,
ylim=YLIM,
xlab = "Days", ylab="Obama - McCain"))
} else{
ind <- sort(sample(1:nrow(polls_2008), replace = TRUE))
tmp <- polls_2008[ind,]
fit <- rpart(margin~day, data = tmp)
pred <- predict(fit, newdata = tmp)
res[[i]] <- tibble(day = tmp$day, margin=pred)
pred <- predict(fit, newdata = polls_2008)
sum <- sum+pred
avg <- sum/i
with(tmp, plot(day,margin, pch=1, xlim=XLIM, ylim=YLIM, type="n",
xlab = "Days", ylab="Obama - McCain",
main=ifelse(i==1, paste(i, "tree"),paste(i, "trees"))))
for(j in 1:i){
with(res[[j]], lines(day, margin, type="s", col="grey", lty=2))
}
with(tmp, points(day,margin, pch=1))
with(res[[i]], lines(day, margin, type="s",col="azure4",lwd=2))
lines(polls_2008$day, avg, lwd=3, col="blue")
}
}
for(i in 1:5){
with(polls_2008, plot(day, margin, pch = 1, main="Final", xlim=XLIM, ylim=YLIM,
xlab = "Days", ylab="Obama - McCain"))
lines(polls_2008$day, avg, lwd=3, col="blue")
}
}, movie.name = "treeFigs/rf.gif", ani.loop=0, ani.delay =50)
}
knitr::opts_chunk$set(echo = TRUE, fig.align="center")
library(caret)
library(tidyverse)
library(kableExtra)
library(gridExtra)
library(tidyverse)
library(dslabs)
data("olive")
olive <- select(olive, -area) #remove the `area` column--don't use it
names(olive)
olive %>% head() %>%
knitr::kable() %>% kable_styling(font_size =7)
table(olive$region)
out.width="50%"}
library(caret)
fit <- train(region ~ .,  method = "knn", data = olive,
tuneGrid = data.frame(k = seq(1, 15, 2)))
ggplot(fit)
