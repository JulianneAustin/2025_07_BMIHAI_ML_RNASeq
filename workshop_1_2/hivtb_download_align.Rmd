---
title: "RNA-Seq Alignment Example"
author: W. Evan Johnson
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: show
    toc: true
    toc_float: true
    theme: "flatly"
editor_options: 
  chunk_output_type: console
---

## Set up: load these packages!
```{r setup, include=F}
suppressMessages({
  library(umap)
  library(DT)
  library(tidyverse)
  library(SummarizedExperiment)
  library(TBSignatureProfiler)
})
```

```{r, eval=F}
library(umap)
library(DT)
library(tidyverse)
library(SummarizedExperiment)
library(TBSignatureProfiler)
```

## SRA - Sequencing Read Archive

- Raw sequencing data and alignment info
- Metagenomics, environmental samples, biomedical sequencing

Download via:

- SRA-toolkit
- FTP links on EMBL ENA

### A quick demonstration of SRA-toolkit and EMBL-ENA

- SRA-toolkit is the official tool released by NCBI to directly download SRA files
  - Notorious for being obtuse to use and confusing commands / documentation
- EMBL-ENA hosts FTP links directly
  - Most but not all SRA accessions available
  - Have to use wget, curl, or other methods to download

### Download a single file
[Download a file for an asthma host microbiome dataset](https://pubmed.ncbi.nlm.nih.gov/26277095/)

```{bash, eval=F}
## attach the sratoolkit
module load sratoolkit

## Save accession to download
acc="SRR1528344"

## Download using fastq-dump 
fastq-dump $acc
# option --split-3 is needed for paired end reads

## don't forget to compress the file!
gzip $acc.fastq
```

### Download all files (serially)

[Download all files for an asthma host microbiome dataset](https://pubmed.ncbi.nlm.nih.gov/26277095/)
```{bash, eval=F}
accs=( $( cat SRR_Acc_List_asthma.txt ) )
for i in $(seq 0 ${#accs[@]}) 
do 
	fastq-dump ${accs[i]};
	gzip ${accs[i]}*
done
```

## Download all files (serially) using batch script in SLURM

```{bash, eval=F}
#!/bin/bash
#SBATCH --job-name=microbiome_download
#SBATCH --mem=1G
#SBATCH --time=01:00:00

module load sratoolkit
cd $HOME/tmp/

accs=( $( cat SRR_Acc_List_asthma.txt ) )
for i in $(seq 0 ${#accs[@]}) 
do 
	fastq-dump ${accs[i]};
	gzip ${accs[i]}*
done
```
Save as a file and use `sbatch` to submit

## Download all files in parallel using batch batch array in SLURM

```{bash, eval=F}
#!/bin/bash
#SBATCH --job-name=microbiome_download
#SBATCH --output=asthma.out
#SBATCH --array=0-27
#SBATCH --cpus-per-task=1
#SBATCH --mem=1G
#SBATCH --time=00:20:00

mkdir -p /scratch/$USER/asthma_data
cd /scratch/$USER/asthma_data

module load sratoolkit

accs=( $( cat SRR_Acc_List_asthma.txt ) )
acc_number=${accs[$SLURM_ARRAY_TASK_ID]}

fastq-dump --gzip $acc_number
```

Save as a file and use `sbatch` to submit

## Download the HIV TB dataset
```{bash, eval=F}
#!/bin/bash
#SBATCH --job-name=hivtb_download
#SBATCH --output=hivtb.out
#SBATCH --array=0-32
#SBATCH --cpus-per-task=1
#SBATCH --mem=1G
#SBATCH --time=00:20:00

mkdir -p /scratch/$USER/hivtb_data
cd /scratch/$USER/hivtb_data

module load sratoolkit

accs=( $( cat SRR_Acc_List_hivtb.txt ) )
acc_number=${accs[$SLURM_ARRAY_TASK_ID]}

fastq-dump --gzip $acc_number
```

## Generate FastQC reports

```{bash, eval=F}	
module load FastQC
fastqc *.fastq.gz --outdir=fastqc/
```

Or add the following to your SLURM script
```{bash, eval=F}
module load FastQC
fastqc $acc_number.fastq.gz --outdir=fastqc/
```

## Generate a MultiQC report
```{bash, eval=F}
module load miniconda
pip install multiqc
cd fastqc/
multiqc .
```


## STAR Alignment

### Download and index the human genome
```{bash, eval=F}
#!/bin/bash
#SBATCH --job-name=build_star_index
#SBATCH --output=star_index.out
#SBATCH --cpus-per-task=8
#SBATCH --mem=32G
#SBATCH --time=04:00:00

# Define variables
GENOME_DIR=/scratch/$USER/star_index
GENOME_FASTA=GRCh38.primary_assembly.genome.fa
GTF_FILE=gencode.v44.annotation.gtf

# Make directories
mkdir -p $GENOME_DIR
cd $GENOME_DIR

# Load STAR and wget
module load STAR
module load wget

# Download genome FASTA and GTF from GENCODE
wget https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_44/$GENOME_FASTA
wget https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_44/$GTF_FILE

# Build the STAR index
STAR --runThreadN 8 \
     --runMode genomeGenerate \
     --genomeDir $GENOME_DIR \
     --genomeFastaFiles $GENOME_FASTA \
     --sjdbGTFfile $GTF_FILE \
     --sjdbOverhang 100  # For 100bp reads
```

### Complete SLURM script

```{bash, eval=F}
#!/bin/bash
#SBATCH --job-name=hivtb_align
#SBATCH --output=hivtb_%A_%a.out
#SBATCH --array=0-32
#SBATCH --cpus-per-task=4
#SBATCH --mem=12G
#SBATCH --time=01:00:00

# Set paths
WORKDIR=/scratch/$USER/hivtb_data
GENOME_INDEX=/scratch/$USER/star_index/human_STAR_GRCh38.primary_assembly.genome.fa  # <-- UPDATE this path if needed

# Create and move to working directory
mkdir -p $WORKDIR
cd $WORKDIR

# Load modules
module load sratoolkit
module load FastQC
module load STAR

# Read accession list and select the task's SRR number
accs=( $(cat $SLURM_SUBMIT_DIR/SRR_Acc_List_hivtb.txt) )
acc_number=${accs[$SLURM_ARRAY_TASK_ID]}

# Download FASTQ
echo "[$acc_number] Downloading FASTQ ..."
fastq-dump --gzip $acc_number

# Run FastQC
mkdir -p fastqc
echo "[$acc_number] Running FastQC ..."
fastqc ${acc_number}.fastq.gz --outdir=fastqc/

# STAR alignment
mkdir -p star_alignments/${acc_number}
echo "[$acc_number] Running STAR alignment ..."
STAR --runThreadN 4 \
     --genomeDir $GENOME_INDEX \
     --readFilesIn ${acc_number}.fastq.gz \
     --readFilesCommand zcat \
     --outFileNamePrefix star_alignments/${acc_number}/ \
     --outSAMtype BAM SortedByCoordinate

echo "[$acc_number] STAR alignment completed."
```


## Session Info
```{r session}
sessionInfo()
```
